import torch
import torch.nn as nn
import numpy as np
import math
import torchaudio
from perceptual_loss import *


s= torch.tensor([-3.60e-02, -3.74e-02, -3.68e-02, -3.03e-02, -2.03e-02, -9.70e-03,
        9.16e-04,  1.08e-02,  1.88e-02,  2.47e-02,  2.57e-02,  2.20e-02,
        1.92e-02,  1.88e-02,  1.87e-02,  1.82e-02,  1.73e-02,  1.72e-02,
        1.89e-02,  2.11e-02,  1.97e-02,  1.51e-02,  9.52e-03,  2.50e-03,
       -6.96e-03, -1.65e-02, -2.37e-02, -2.73e-02, -2.66e-02, -2.44e-02,
       -2.29e-02, -1.97e-02, -1.46e-02, -9.19e-03, -5.28e-03, -3.81e-03,
       -4.06e-03, -4.21e-03, -3.39e-03, -2.04e-03,  1.50e-03,  9.52e-03,
        1.90e-02,  2.59e-02,  2.98e-02,  2.98e-02,  2.88e-02,  2.75e-02,
        2.31e-02,  1.53e-02,  7.08e-03,  4.88e-04, -5.00e-03, -8.30e-03,
       -9.43e-03, -8.94e-03, -7.39e-03, -5.95e-03, -6.96e-03, -9.16e-03,
       -9.92e-03, -1.02e-02, -1.06e-02, -1.14e-02, -1.19e-02, -1.04e-02,
       -7.11e-03, -2.84e-03,  1.40e-03,  5.13e-03,  7.87e-03,  8.51e-03,
        7.32e-03,  5.16e-03,  2.99e-03,  1.43e-03, -6.10e-05, -2.17e-03,
       -3.81e-03, -3.51e-03, -2.11e-03, -3.66e-04,  5.80e-04,  7.32e-04,
        1.22e-04, -1.68e-03, -4.36e-03, -7.02e-03, -8.94e-03, -1.01e-02,
       -1.10e-02, -1.20e-02, -1.29e-02, -1.28e-02, -1.15e-02, -9.95e-03,
       -9.67e-03, -9.98e-03, -1.01e-02, -1.10e-02, -1.21e-02, -1.17e-02,
       -1.10e-02, -1.06e-02, -9.98e-03, -6.62e-03, -5.16e-03, -5.19e-03,
       -1.34e-03,  1.53e-04, -8.24e-04, -2.96e-03, -4.58e-03, -3.05e-03,
        2.17e-03,  1.53e-02,  3.26e-02,  4.55e-02,  5.21e-02,  5.66e-02,
        5.65e-02,  5.14e-02,  4.32e-02,  3.15e-02,  1.83e-02,  3.94e-03,
       -7.72e-03, -1.64e-02, -2.30e-02, -2.43e-02, -2.08e-02, -1.79e-02,
       -1.96e-02, -2.34e-02, -2.67e-02, -2.84e-02, -3.13e-02, -3.45e-02,
       -3.51e-02, -3.37e-02, -2.83e-02, -1.90e-02, -8.06e-03,  3.23e-03,
        1.54e-02,  2.66e-02,  3.25e-02,  3.24e-02,  3.05e-02,  2.94e-02,
        2.69e-02,  2.21e-02,  1.68e-02,  1.27e-02,  1.14e-02,  1.16e-02,
        1.23e-02,  1.21e-02,  1.02e-02,  7.23e-03,  2.23e-03, -6.41e-03,
       -1.59e-02, -2.22e-02, -2.60e-02, -2.89e-02, -3.13e-02, -3.08e-02,
       -2.63e-02, -1.97e-02, -1.20e-02, -5.00e-03, -9.16e-05,  3.30e-03,
        5.37e-03,  5.58e-03,  6.20e-03,  9.61e-03,  1.53e-02,  2.04e-02,
        2.26e-02,  2.29e-02,  2.39e-02,  2.60e-02,  2.65e-02,  2.38e-02,
        1.88e-02,  1.21e-02,  4.52e-03, -2.53e-03, -8.45e-03, -1.24e-02,
       -1.42e-02, -1.44e-02, -1.50e-02, -1.54e-02, -1.40e-02, -1.03e-02,
       -6.74e-03, -5.19e-03, -5.25e-03, -5.58e-03, -5.62e-03, -5.10e-03,
       -3.69e-03, -1.68e-03,  5.19e-04,  2.29e-03,  3.48e-03,  4.21e-03,
        5.22e-03,  6.38e-03,  6.81e-03,  5.13e-03,  1.98e-03, -9.77e-04,
       -2.69e-03, -3.60e-03, -4.24e-03, -4.12e-03, -3.57e-03, -3.48e-03,
       -3.88e-03, -4.24e-03, -4.33e-03, -4.55e-03, -5.62e-03, -8.00e-03,
       -1.12e-02, -1.38e-02, -1.48e-02, -1.46e-02, -1.44e-02, -1.43e-02,
       -1.31e-02, -1.20e-02, -1.18e-02, -1.03e-02, -8.03e-03, -7.87e-03,
       -6.62e-03, -4.91e-03, -5.80e-03, -7.72e-03, -5.07e-03, -1.80e-03,
       -5.43e-03, -7.08e-03, -3.45e-03, -2.96e-03, -2.11e-03,  1.09e-02,
        2.92e-02,  4.15e-02,  5.08e-02,  5.74e-02,  5.75e-02,  5.29e-02,
        4.79e-02,  3.99e-02,  2.58e-02,  1.04e-02, -1.46e-03, -1.06e-02,
       -1.95e-02, -2.55e-02, -2.46e-02, -1.94e-02, -1.92e-02, -2.31e-02,
       -2.50e-02, -2.65e-02, -2.94e-02, -3.05e-02, -3.16e-02, -3.49e-02,
       -3.42e-02, -2.62e-02, -1.67e-02, -8.85e-03,  2.23e-03,  1.64e-02,
        2.72e-02,  3.16e-02,  3.26e-02,  3.30e-02,  3.31e-02,  3.03e-02,
        2.44e-02,  1.79e-02,  1.22e-02,  9.46e-03,  1.00e-02,  1.00e-02,
        7.90e-03,  7.05e-03,  7.63e-03,  3.60e-03, -4.88e-03, -1.19e-02,
       -1.59e-02, -2.08e-02, -2.65e-02, -3.09e-02, -3.28e-02, -3.06e-02,
       -2.44e-02, -1.72e-02, -1.07e-02, -4.52e-03,  1.53e-03,  6.56e-03,
        1.02e-02,  1.39e-02,  1.77e-02,  2.14e-02,  2.23e-02,  1.92e-02,
        1.76e-02,  1.86e-02,  1.97e-02,  1.98e-02,  1.90e-02,  1.63e-02,
        1.21e-02,  8.15e-03,  4.24e-03, -1.10e-03, -5.77e-03, -9.00e-03,
       -1.30e-02, -1.73e-02, -1.91e-02, -1.71e-02, -1.32e-02, -9.92e-03,
       -7.69e-03, -5.22e-03, -2.93e-03, -1.43e-03, -5.19e-04,  2.14e-04,
        2.44e-04, -5.49e-04, -1.37e-03, -2.26e-03, -2.59e-03, -8.24e-04,
        1.89e-03,  2.84e-03,  2.59e-03,  2.29e-03,  2.41e-03,  2.23e-03,
        1.37e-03, -3.05e-05, -1.40e-03, -3.08e-03, -5.10e-03, -6.50e-03,
       -6.74e-03, -6.35e-03, -5.86e-03, -6.04e-03, -7.35e-03, -9.06e-03,
       -1.01e-02, -1.06e-02, -1.21e-02, -1.39e-02, -1.53e-02, -1.63e-02,
       -1.63e-02, -1.48e-02, -1.38e-02, -1.19e-02, -7.66e-03, -6.68e-03,
       -7.48e-03, -4.33e-03, -2.35e-03, -3.72e-03, -3.27e-03, -4.24e-03,
       -6.96e-03, -6.96e-03, -1.46e-03,  8.15e-03,  2.14e-02,  3.74e-02,
        4.97e-02,  5.56e-02,  5.90e-02,  5.89e-02,  5.43e-02,  4.66e-02,
        3.44e-02,  1.88e-02,  4.82e-03, -7.66e-03, -1.93e-02, -2.55e-02,
       -2.61e-02, -2.47e-02, -2.30e-02, -2.21e-02, -2.29e-02, -2.42e-02,
       -2.37e-02, -2.47e-02, -2.90e-02, -3.26e-02, -3.33e-02, -3.21e-02,
       -2.79e-02, -2.04e-02, -1.03e-02,  2.38e-03,  1.47e-02,  2.39e-02,
        2.98e-02,  3.47e-02,  3.77e-02,  3.71e-02,  3.32e-02,  2.64e-02,
        1.88e-02,  1.36e-02,  1.02e-02,  6.81e-03,  5.58e-03,  6.59e-03,
        6.93e-03,  5.71e-03,  3.36e-03, -6.10e-05, -3.85e-03, -8.00e-03,
       -1.44e-02, -2.22e-02, -2.85e-02, -3.15e-02, -3.20e-02, -2.97e-02,
       -2.51e-02, -1.90e-02, -1.15e-02, -3.66e-03,  4.18e-03,  1.22e-02,
        1.79e-02,  2.22e-02,  2.39e-02,  2.11e-02,  1.79e-02,  1.58e-02,
        1.46e-02,  1.32e-02,  1.20e-02,  1.21e-02,  1.19e-02,  1.15e-02,
        1.14e-02,  1.03e-02,  8.42e-03,  5.19e-03,  4.27e-04, -5.28e-03,
       -1.09e-02, -1.44e-02, -1.60e-02, -1.64e-02, -1.59e-02, -1.38e-02,
       -1.04e-02, -6.74e-03, -3.60e-03, -7.32e-04,  1.71e-03,  1.95e-03,
        5.80e-04, -1.59e-03, -3.60e-03, -5.07e-03, -5.55e-03, -5.40e-03,
       -4.76e-03, -3.54e-03, -1.13e-03,  1.46e-03,  3.63e-03,  5.40e-03,
        6.26e-03,  5.80e-03,  3.78e-03,  9.46e-04, -1.77e-03, -4.15e-03,
       -6.50e-03, -8.70e-03, -1.01e-02, -1.10e-02, -1.09e-02, -1.01e-02,
       -9.37e-03, -8.85e-03, -8.73e-03, -9.86e-03, -1.17e-02, -1.28e-02,
       -1.36e-02, -1.51e-02])


sr = torch.tensor([-0.04, -0.04, -0.04, -0.03, -0.02, -0.01,  0.  ,  0.01,  0.02,
        0.03,  0.03,  0.02,  0.02,  0.02,  0.02,  0.02,  0.02,  0.02,
        0.02,  0.02,  0.02,  0.02,  0.01,  0.  , -0.01, -0.02, -0.02,
       -0.03, -0.03, -0.03, -0.02, -0.02, -0.01, -0.01, -0.  , -0.  ,
       -0.  , -0.  , -0.  , -0.  ,  0.  ,  0.01,  0.02,  0.03,  0.03,
        0.03,  0.03,  0.03,  0.02,  0.02,  0.01,  0.  , -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.  ,  0.  ,  0.01,  0.01,  0.01,
        0.01,  0.01,  0.  ,  0.  , -0.  , -0.  , -0.  , -0.  , -0.  ,
       -0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  , -0.01, -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.  ,
       -0.  ,  0.  , -0.  , -0.  , -0.  , -0.  ,  0.  ,  0.02,  0.03,
        0.05,  0.05,  0.06,  0.06,  0.05,  0.04,  0.03,  0.02,  0.  ,
       -0.01, -0.02, -0.02, -0.03, -0.02, -0.02, -0.02, -0.02, -0.03,
       -0.03, -0.03, -0.03, -0.04, -0.03, -0.03, -0.02, -0.01,  0.  ,
        0.02,  0.03,  0.03,  0.03,  0.03,  0.03,  0.03,  0.02,  0.02,
        0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.  , -0.01,
       -0.01, -0.02, -0.03, -0.03, -0.03, -0.03, -0.03, -0.02, -0.01,
       -0.  ,  0.  ,  0.  ,  0.  ,  0.01,  0.01,  0.01,  0.01,  0.02,
        0.02,  0.02,  0.02,  0.03,  0.03,  0.02,  0.02,  0.01,  0.01,
       -0.  , -0.01, -0.01, -0.02, -0.02, -0.02, -0.01, -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.  , -0.  , -0.  , -0.  ,  0.  ,
        0.  ,  0.  ,  0.  ,  0.01,  0.01,  0.01,  0.  ,  0.  ,  0.  ,
       -0.  , -0.  , -0.01, -0.01, -0.  , -0.  , -0.  , -0.  , -0.  ,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.02, -0.02, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.  , -0.01,
       -0.01, -0.  , -0.  , -0.01, -0.01, -0.  , -0.  , -0.  ,  0.01,
        0.03,  0.04,  0.05,  0.06,  0.06,  0.05,  0.05,  0.04,  0.03,
        0.01, -0.  , -0.01, -0.02, -0.03, -0.02, -0.02, -0.02, -0.02,
       -0.03, -0.03, -0.03, -0.03, -0.03, -0.03, -0.03, -0.03, -0.02,
       -0.01,  0.  ,  0.02,  0.03,  0.03,  0.03,  0.03,  0.03,  0.03,
        0.02,  0.02,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,
        0.  , -0.  , -0.01, -0.02, -0.02, -0.03, -0.03, -0.03, -0.03,
       -0.02, -0.02, -0.01, -0.  ,  0.  ,  0.01,  0.01,  0.01,  0.02,
        0.02,  0.02,  0.02,  0.02,  0.02,  0.02,  0.02,  0.02,  0.02,
        0.01,  0.01,  0.  , -0.  , -0.01, -0.01, -0.01, -0.02, -0.02,
       -0.02, -0.01, -0.01, -0.01, -0.  , -0.  , -0.  , -0.  ,  0.  ,
        0.  , -0.  , -0.  , -0.  , -0.  , -0.  ,  0.  ,  0.  ,  0.  ,
        0.  ,  0.  ,  0.  ,  0.  ,  0.  , -0.  , -0.  , -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,
       -0.01, -0.02, -0.02, -0.02, -0.01, -0.01, -0.01, -0.01, -0.01,
       -0.01, -0.  , -0.  , -0.  , -0.  , -0.  , -0.01, -0.01, -0.  ,
        0.01,  0.02,  0.04,  0.05,  0.06,  0.06,  0.06,  0.05,  0.05,
        0.03,  0.02,  0.01, -0.01, -0.02, -0.03, -0.03, -0.03, -0.02,
       -0.02, -0.02, -0.02, -0.02, -0.02, -0.03, -0.03, -0.03, -0.03,
       -0.03, -0.02, -0.01,  0.  ,  0.01,  0.02,  0.03,  0.03,  0.04,
        0.04,  0.03,  0.03,  0.02,  0.01,  0.01,  0.01,  0.01,  0.01,
        0.01,  0.01,  0.  , -0.  , -0.  , -0.01, -0.01, -0.02, -0.03,
       -0.03, -0.03, -0.03, -0.02, -0.02, -0.01, -0.  ,  0.  ,  0.01,
        0.02,  0.02,  0.02,  0.02,  0.02,  0.02,  0.01,  0.01,  0.01,
        0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.  ,  0.  , -0.01,
       -0.01, -0.01, -0.02, -0.02, -0.02, -0.01, -0.01, -0.01, -0.  ,
       -0.  ,  0.  ,  0.  ,  0.  , -0.  , -0.  , -0.  , -0.01, -0.01,
       -0.  , -0.  , -0.  ,  0.  ,  0.  ,  0.  ,  0.01,  0.01,  0.  ,
        0.  , -0.  , -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01,
       -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01])


def no_window(length):
        return torch.ones(length)
    

# FFT_SIZE = 512

# MEL_SCALES = [8, 16, 32, 128]

# MEL_FILTERBANKS = []
# for scale in MEL_SCALES:
#     filterbank_npy = melFilterBank(scale, FFT_SIZE).transpose()
#     MEL_FILTERBANKS.append(filterbank_npy)   

# spec = torchaudio.transforms.Spectrogram(n_fft=512, window_fn=no_window)

# n = 8
# melspec = torchaudio.transforms.MelSpectrogram(n_fft=512, n_mels=n, window_fn=no_window)

# def spec_melbank(s):
#     s_spec = spec(s)[:,1][:, None]*1/512
#     s_spec_melbank = torch.log(torch.mm(s_spec.T, torch.tensor(MEL_FILTERBANKS[0], dtype=torch.float)) + 1e-20)
#     return s_spec_melbank

# # print(torch.sqrt(spec(s)[:,1])+1e-20)

# s_spec_melbank = spec_melbank(s)
# print(s_spec_melbank)

# sr_spec_melbank = spec_melbank(sr)
# print(sr_spec_melbank)

# s_melspec = melspec(s)[:,1]
# print(s_melspec)

# s_spec = spec(sr)[:,1][:, None]*1/512
# melscale = torchaudio.transforms.MelScale(n_mels=8, sample_rate=SAMPLE_RATE, f_min=0, f_max = SAMPLE_RATE / 2, n_stft = 257)
# melspec3 = torch.log(melscale(s_spec)) + 1e-20
# print(melspec3)

def melMSELoss(s, sr, n_mels = [8, 16, 32, 128]): 
    
    assert s.shape[1] == 512
    assert sr.shape[1] == 512
    
    loss = 0
    eps = 1e-20
    mse = nn.MSELoss().cuda()
    s = s.cuda()
    sr = sr.cuda()
    
    def no_window(length):
        return torch.ones(length)
    
    FFT_SIZE = 512
#     MEL_SCALES = [8, 16, 32, 128]
    MEL_FILTERBANKS = []
    
    for scale in n_mels:
        filterbank_npy = melFilterBank(scale, FFT_SIZE).transpose()
        filterbank_npy = torch.tensor(filterbank_npy, dtype=torch.float, device='cuda')
        MEL_FILTERBANKS.append(filterbank_npy)

    spec = torchaudio.transforms.Spectrogram(n_fft=512, window_fn=no_window).cuda()
    
    s_spec = spec(s)[:,:,1]/FFT_SIZE
    sr_spec = spec(sr)[:,:,1]/FFT_SIZE
#     print(s_spec.shape)
#     print(MEL_FILTERBANKS[0].shape)
    for filterbank in MEL_FILTERBANKS:
        # s_spec.shape -> [Batch, 257]
        # filterbank -> [257, 8]
        s_melspec = torch.log(torch.matmul(s_spec, filterbank) + 1e-20)
        sr_melspec = torch.log(torch.matmul(sr_spec, filterbank) + 1e-20)

        error = torch.sqrt(mse(s_melspec, sr_melspec))
        loss += error
        
    return loss/len(n_mels)

print(melMSELoss(s[None, :], sr[None,:]))